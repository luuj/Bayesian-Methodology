}
print(paste("iteration", a, "done"))
proc.time()-ptm
}
library(doParallel)
registerDoParallel(detectCores())
i_length
help("matrix")
dim(s_kv)
knitr::opts_chunk$set(echo = TRUE, fig.width = 6, fig.height = 4, comment = NA)
ap <- read.csv("C:\\Users\\Jonathan\\OneDrive - Harvard University\\School\\Harvard\\BST249\\Homework 5\\ap.csv", col.names=paste0("V",seq_len(640)), header=FALSE)
vocab <- read.table("C:\\Users\\Jonathan\\OneDrive - Harvard University\\School\\Harvard\\BST249\\Homework 5\\vocab.txt")
library(doParallel)
registerDoParallel(detectCores())
# Run the algorithm
for(a in 1:150){
# Compute first term
term1 <- digamma(r_ik) - digamma(apply(r_ik, 1, sum))
# Compute second term
term2 <- digamma(s_kv) - digamma(apply(s_kv,1, sum))
s_kv <- matrix(rep(lambda,K), nrow=K, ncol=V, byrow = TRUE)
for(i in 1:i_length){
# Get length of the current document
L_i <- calcLength(ap[i,])
# Get vocab list of the current document
currentV <- unlist(ap[i,1:L_i])
# Calculate T
T_matrix <- term1[i,] + term2[,currentV]
# Update r_ik
r_ik[i,] <- alpha + apply(T_matrix,1,sum)
# Update s_kv
s_kv[,currentV] <- s_kv[,currentV] + T_matrix
}
print(paste("iteration", a, "done"))
}
r_ik
r_ik
dim(r_ik)
apply(r_ik,2,sum)
apply(r_ik,1,sum)
apply(r_ik,1,sum)
knitr::opts_chunk$set(echo = TRUE, fig.width = 6, fig.height = 4, comment = NA)
ap <- read.csv("C:\\Users\\Jonathan\\OneDrive - Harvard University\\School\\Harvard\\BST249\\Homework 5\\ap.csv", col.names=paste0("V",seq_len(640)), header=FALSE)
vocab <- read.table("C:\\Users\\Jonathan\\OneDrive - Harvard University\\School\\Harvard\\BST249\\Homework 5\\vocab.txt")
cat_pop <- numeric(25)
cat_pop
r_ik
r_ik[1,]
sum(r_ik[1,])
i=1
r_ik[i,]/curr_r_sum
curr_r_sum <- sum(r_ik[i,])
r_ik[i,]/curr_r_sum
cat_pop <- cat_pop + r_ik[i,]/curr_r_sum
cat_pop <- numeric(25)
for (i in 1:2246){
curr_r_sum <- sum(r_ik[i,])
cat_pop <- cat_pop + r_ik[i,]/curr_r_sum
}
cat_pop
sort(cat_pop)
sort(cat_pop)[18:25]
which(cat_pop==sort(cat_pop)[18:25])
sort(cat_pop, index.return=TRUE)
dim(s_kv)
s_kv[8,]
s_kv[8,] / sum(s_kv[8,])
sort(s_kv[8,] / sum(s_kv[8,]), index.return=TRUE)
-1:-20
sort(s_kv[8,] / sum(s_kv[8,]), index.return=TRUE)[-1:-20]
end(s_kv)
sort(s_kv[8,] / sum(s_kv[8,]), index.return=TRUE)$ix
tail(sort(s_kv[8,] / sum(s_kv[8,]), index.return=TRUE)$ix)
tail(sort(s_kv[8,] / sum(s_kv[8,]), index.return=TRUE)$ix, n=20)
word_pop <- matrix(0, nrow=8, ncol=20)
for (k in 1:8){
word_pop[k,] <- tail(sort(s_kv[k,] / sum(s_kv[k,]), index.return=TRUE)$ix, n=20)
}
word_pop
for (k in c(8,10,21,19,5,22,9,18)){
word_pop[k,] <- tail(sort(s_kv[k,] / sum(s_kv[k,]), index.return=TRUE)$ix, n=20)
}
curr_i <- 1
for (k in c(8,10,21,19,5,22,9,18)){
word_pop[curr_i,] <- tail(sort(s_kv[k,] / sum(s_kv[k,]), index.return=TRUE)$ix, n=20)
curr_i <- curr_i + 1
}
word_pop
vocab[word_pop[1,],1]
vocab[word_pop[2,],1]
tail(sort(s_kv[k,] / sum(s_kv[k,]), index.return=TRUE)$ix, n=20)
tail(sort(s_kv[k,] / sum(s_kv[k,]), index.return=TRUE), n=20)
for (k in c(8,10,21,19,5,22,9,18)){
word_pop[curr_i,] <- tail(sort(s_kv[k,] / sum(s_kv[k,]), index.return=TRUE)$ix, n=20)
word_prop[curr_i,] <- tail(sort(s_kv[k,] / sum(s_kv[k,]), index.return=TRUE)$x, n=20)
curr_i <- curr_i + 1
}
curr_i <- 1
for (k in c(8,10,21,19,5,22,9,18)){
word_pop[curr_i,] <- tail(sort(s_kv[k,] / sum(s_kv[k,]), index.return=TRUE)$ix, n=20)
word_prop[curr_i,] <- tail(sort(s_kv[k,] / sum(s_kv[k,]), index.return=TRUE)$x, n=20)
curr_i <- curr_i + 1
}
word_pop <- matrix(0, nrow=8, ncol=20)
word_prop <-  matrix(0, nrow=8, ncol=20)
curr_i <- 1
for (k in c(8,10,21,19,5,22,9,18)){
word_pop[curr_i,] <- tail(sort(s_kv[k,] / sum(s_kv[k,]), index.return=TRUE)$ix, n=20)
word_prop[curr_i,] <- tail(sort(s_kv[k,] / sum(s_kv[k,]), index.return=TRUE)$x, n=20)
curr_i <- curr_i + 1
}
word_prop
word_pop <- matrix(0, nrow=8, ncol=20)
curr_i <- 1
for (k in c(8,10,21,19,5,22,9,18)){
word_pop[curr_i,] <- tail(sort(s_kv[k,] / sum(s_kv[k,]), index.return=TRUE)$ix, n=20)
curr_i <- curr_i + 1
}
vocab[word_pop[1,],]
vocab[word_pop[2,],]
vocab[word_pop[3,],]
vocab[word_pop[4,],]
vocab[word_pop[5,],]
vocab[word_pop[6,],]
vocab[word_pop[7,],]
vocab[word_pop[8,],]
knitr::opts_chunk$set(echo = TRUE)
sum(x)
x <- c(13,7,11,12,4,3,11,3,5)
y <- c(10,7,13,17,8,1,15,7,4)
sum(x)
sum(y)
sd(x)
sd(x)
sd(y)
B <- t_y/t_x
t_x <- sum(x)
t_y <- sum(y)
S_x <- sd(x)
S_y <- sd(y)
B <- t_y/t_x
B
t_x
t_y
S_x
S_y
1+2+3+4
1+2+3+44
4+5+5+6
20/4
x
x-mean(x)
(x-mean(x))*(y-mean(y))
sum((x-mean(x))*(y-mean(y)))
sum((x-mean(x))*(y-mean(y))) / ((9-1)*S_x*S_y )
choose(9,3)
library(gtools)
combinations(9,3)
sample_vals_index <- combinations(9,3)
sample_vals <- x[sample_vals_index]
sample_vals
length(sample_vals)
84*3
length(sample_vals)
sample_vals <- matrix(x[sample_vals_index], ncol=3)
sample_vals
sample_vals <- cbind(matrix(x[sample_vals_index], ncol=3),
matrix(y[sample_vals_index], ncol=3))
sample_vals
colnames(sample_vals) <- c("x1", "x2", "x3", "y1", "y2", "y3")
sample_vals
sample_vals_index
head(sample_vals)
sample_vals_index <- combinations(9,3)
sample_vals_x <- matrix(x[sample_vals_index], ncol=3)
sample_vals_y <- matrix(y[sample_vals_index], ncol=3)
head(sample_vals_x)
apply(sample_vals_x, 1, mean)
sample_vals_index$x_bar <- apply(sample_vals_x, 1, mean)
sample_vals_index
sample_vals_index <- combinations(9,3)
sample_vals_index
sample_vals_index <- data.frame(combinations(9,3))
sample_vals_index
sample_vals_index$x_bar <- apply(sample_vals_x, 1, mean)
sample_vals_index
colnames(sample_vals_index) <- c("S1", "S2", "S3")
head(sample_vals_index)
sample_vals_index$x_bar <- apply(sample_vals_x, 1, mean)
head(sample_vals_index)
sample_vals_index <- data.frame(combinations(9,3))
colnames(sample_vals_index) <- c("S1", "S2", "S3")
sample_vals_index$x_bar <- apply(sample_vals_x, 1, mean)
head(sample_vals_index)
sample_vals_index$y_bar <- apply(sample_vals_y, 1, mean)
head(sample_vals_index)
2.75/5
head(sample_vals_index)
sample_vals_index$y_bar/sample_vals_index$x_bar
sample_vals_index$B <- sample_vals_index$y_bar/sample_vals_index$x_bar
sample_vals_index
0.55*230
0.55*20
5.50*4
22/0.64
5*0.55
8*2.75
sample_vals_index$t_SRS <- 9*y_bar
sample_vals_index$t_SRS <- 9*sample_vals_index$y_bar
head(sample_vals_index)
4+5+5+6
20*0.55
20*(1/.55)
1+2+4+4
11*.55
20*.55
22*.55
t_x
25.85/5
25.85/0.55
25.85*0.55
4+5+5+8
22*0.64
5+7+9+10
31*.55
4+5+5+6+8+7+7+5
47*.55
47(.64)
sample_vals_index$t_yr <- t_x*sample_vals_index$B
head(sample_vals_index)
N <- 9
N <- 8
x <- c(4,5,5,6,8,7,7,5)
y <- c(1,2,4,4,7,7,7,8)
t_x <- sum(x)
t_y <- sum(y)
S_x <- sd(x)
S_y <- sd(y)
B <- t_y/t_x
R <- sum((x-mean(x))*(y-mean(y))) / ((N-1)*S_x*S_y )
t_x
t_y
S_x
S_y
R
B
sample_vals_index <- data.frame(combinations(N,3))
colnames(sample_vals_index) <- c("S1", "S2", "S3")
sample_vals_x <- matrix(x[sample_vals_index], ncol=3)
sample_vals_index <- data.frame(combinations(N,4))
sample_vals_index
sample_vals_x <- matrix(x[sample_vals_index], ncol=4)
sample_vals_index <- combinations(N,4)
sample_vals_x <- matrix(x[sample_vals_index], ncol=4)
sample_vals_y <- matrix(y[sample_vals_index], ncol=4)
sample_vals_x
sample_vals_x <- matrix(x[sample_vals_index], ncol=4)
sample_vals_y <- matrix(y[sample_vals_index], ncol=4)
sample_vals_index$x_bar <- apply(sample_vals_x, 1, mean)
sample_vals_index$y_bar <- apply(sample_vals_y, 1, mean)
sample_vals_index$B <- sample_vals_index$y_bar/sample_vals_index$x_bar
sample_vals_index$t_SRS <- 9*sample_vals_index$y_bar
sample_vals_index$t_yr <- t_x*sample_vals_index$B
sample_vals_index <- data.frame(combinations(N,4))
sample_vals_index$x_bar <- apply(sample_vals_x, 1, mean)
sample_vals_index$y_bar <- apply(sample_vals_y, 1, mean)
sample_vals_index$B <- sample_vals_index$y_bar/sample_vals_index$x_bar
sample_vals_index$t_SRS <- 9*sample_vals_index$y_bar
sample_vals_index$t_yr <- t_x*sample_vals_index$B
head(sample_vals_index)
N
8*2.75
sample_vals_index$t_SRS <- N*sample_vals_index$y_bar
head(sample_vals_index)
library(gtools)
N <- 9
x <- c(13,7,11,12,4,3,11,3,5)
y <- c(10,7,13,17,8,1,15,7,4)
t_x <- sum(x)
t_y <- sum(y)
S_x <- sd(x)
S_y <- sd(y)
B <- t_y/t_x
R <- sum((x-mean(x))*(y-mean(y))) / ((N-1)*S_x*S_y )
sample_vals_index <- data.frame(combinations(N,3))
colnames(sample_vals_index) <- c("S1", "S2", "S3")
sample_vals_x <- matrix(x[combinations(N,3)], ncol=3)
sample_vals_y <- matrix(y[combinations(N,3)], ncol=3)
sample_vals_index$x_bar <- apply(sample_vals_x, 1, mean)
sample_vals_index$y_bar <- apply(sample_vals_y, 1, mean)
sample_vals_index$B <- sample_vals_index$y_bar/sample_vals_index$x_bar
sample_vals_index$t_SRS <- N*sample_vals_index$y_bar
sample_vals_index$t_yr <- t_x*sample_vals_index$B
sample_vals_index
knitr::opts_chunk$set(echo = TRUE, comment=NA)
library(gtools)
# Histogram of Ny_bar and t_yr
hist(sample_vals_index$t_SRS)
knitr::opts_chunk$set(echo = TRUE, comment=NA, fig.width = 6, fig.height = 4)
library(gtools)
# Histogram of Ny_bar and t_yr
hist(sample_vals_index$t_SRS)
# Histogram of Ny_bar and t_yr
hist(sample_vals_index$t_SRS, breaks=seq(35,140,10))
# Histogram of Ny_bar and t_yr
hist(sample_vals_index$t_SRS, breaks=seq(30,160,10))
# Histogram of Ny_bar and t_yr
hist(sample_vals_index$t_SRS, breaks=seq(30,150,10))
# Histogram of Ny_bar and t_yr
hist(sample_vals_index$t_SRS, breaks=seq(30,145,10))
# Histogram of Ny_bar and t_yr
hist(sample_vals_index$t_SRS, breaks=seq(20,145,10))
# Histogram of Ny_bar and t_yr
hist(sample_vals_index$t_SRS, breaks=seq(20,145,5))
hist(sample_vals_index$t_yr, breaks=seq(20,145,5))
R <- sum((x-mean(x))*(y-mean(y))) / ((N-1)*S_x*S_y )
R
mean(sample_vals_index$t_yr)
mean(sample_vals_index$t_SRS)
var(sample_vals_index$t_SRS)
var(sample_vals_index$t_yr)
t_y
mean(sample_vals_index$t_yr)
mean(x)
B
S_x
S_x^2
R
S_y
1-(3/9)
2/3
(2/3)*(1/(3*7.67))*(1.19*16.75-0.81*4.09*5.18)
mean(sample_vals_index$t_yr)
x
mean(x)
(2/3)*(1/(3*7.67^2))*(1.19*16.75-0.81*4.09*5.18)
(2/3)*(1/(3*mean(x)))*(B*S_x^2-R*S_x*S_y)
(2/3)*(1/(3*mean(x)^2))*(B*S_x^2-R*S_x*S_y)
ch5.data <- data.frame(c(1471,890,1021,1587), c(792,447,511,800), c(25,15,20,40), c(10,3,6,27))
ch5.data
ch5.data <- data.frame(n_student = c(1471,890,1021,1587), n_female = c(792,447,511,800),
n_interview = c(25,15,20,40), n_smoker = c(10,3,6,27))
ch5.data
ch5.data
10+3+6+27
25+15+20+40
792+447+511+800
ch5.data
N <- 1471+890+1021+1587
n <- 792+447+511+800
N
n
N/n
(N/n) * (25/10)
ch5.data$n_interview/ch5.data$n_smoker
(N/n)*(ch5.data$n_interview/ch5.data$n_smoker)
N <- 29
n <- 4
M <- ch5.data$n_female
m <- ch5.data$n_interview
weight <- (N/n)*(M/m)
weight
M
m
N
n
weight*ch5.data$n_smoker
ch5.data
y <- ch5.data$n_smoker
y
weight*y
weight*(y/m)
ch5.data
mean(weight*(y/m))
y/m
weight*(y/m)
N
n
M
m
weight*y
sum(weight*y)
sum(weight*y)
(M/m)*y
sum((M/m)*y)
ch5.data
t_unb <- sum(weight*y)
t_unb
ti-t_unb
ti <- (M/m)*y
ti-t_unb
s_t2 <- 1/(n-1) * sum((ti-t_unb)^2)
s_t2
var_t_tunb <- N^2*(1-n/N)*s_t2/n
var_t_tunb
sqrt(var_t_tunb)
s_t2 <- 1/(n-1) * sum((ti-t_unb/N)^2)
s_t2
var_t_tunb <- N^2*(1-n/N)*s_t2/n
sqrt(var_t_tunb)
1.96*2706
ch5.data
var_t_tunb <- N^2*(1-n/N)*(s_t2/n)
var_t_tunb <- sqrt(N^2*(1-n/N)*(s_t2/n))
var_t_tunb
N^2 * s_t2/n
sqrt(N^2 * s_t2/n)
sqrt(N^2 * s_t2/n)*1.96
7971-5713
7971+5713
weight
weight/sum(weight)
(weight/sum(weight))*(y/m)
y/m
mean(y/m)
sum(weight)/weight
weight*(y/m)
(weight*(y/m))/sum(weight)
y/m
(y/m)*(weight/sum(weight))
mean((y/m)*(weight/sum(weight)))
sum((y/m)*(weight/sum(weight)))
250*60
15000/30
ch6.data <- read.csv("C:\\Users\\Jonathan\\OneDrive - Harvard University\\School\\Harvard\\BST239\\HW4\\exercise0602.csv")
ch6.data
ch6.data
sum(ch6.data$psi)
cumsum(ch6.data$psi)
ch6.data$cpsi <- cumsum(ch6.data$psi)
ch6.data
# Generate 10 random numbers between 0 and 1
pickNum <- runif(n=10)
pickNum
# Generate 10 random numbers between 0 and 1
set.seed(123)
runif(n=10)
max(ch6.data$psi)
ch6.data$psi[20]
sample_list <- integer(10)
while (curr_size < 10){
item <- runif(n=1, min=1, max=25)
prob <- runif(n=1, min=0, max=max(ch6.data$psi))
if (prob < ch6.data$psi[item]){
sample_list[curr_size] <- item
curr_size <- curr_size + 1
}
}
curr_size <- 0
sample_list <- integer(10)
while (curr_size < 10){
item <- runif(n=1, min=1, max=25)
prob <- runif(n=1, min=0, max=max(ch6.data$psi))
if (prob < ch6.data$psi[item]){
sample_list[curr_size] <- item
curr_size <- curr_size + 1
}
}
sample_list
sample(1:25, 1)
sample(1:25, 1)
sample(1:25, 1)
runif(n=1, min=0, max=max(ch6.data$psi))
ch6.data$psi[7]
0.009534473 < ch6.data$psi[7]
curr_size <- 0
sample_list <- integer(10)
while (curr_size < 10){
item <- sample(1:25, 1)
prob <- runif(n=1, min=0, max=max(ch6.data$psi))
if (prob < ch6.data$psi[item]){
sample_list[curr_size] <- item
curr_size <- curr_size + 1
}
}
sample_list
curr_size <- 0
sample_list <- integer(10)
while (curr_size <= 10){
item <- sample(1:25, 1)
prob <- runif(n=1, min=0, max=max(ch6.data$psi))
if (prob < ch6.data$psi[item]){
sample_list[curr_size] <- item
curr_size <- curr_size + 1
}
}
sample_list
# Simulated data
sim1 <- read.table("C:\\Users\\Jonathan\\Dropbox\\BST249 Group Project\\Simulated_data\\data_Replicates_SAPHIRE\\main_est_SAPHIRE.txt",
header = TRUE)
init_sets_list$daily_new_case <- sim1$Onset_expect
code_root="C:\\Users\\Jonathan\\OneDrive - Harvard University\\School\\Harvard\\BST249\\Project\\BST249 Project Code\\SAPHIRE-master\\"
setwd(paste0(code_root, "scripts_main"))
library(vioplot)
library("corrplot")
library(readr)
library(cairoDevice)
##
source(paste0(code_root, "R/fun_SEIRpred.R"))
source(paste0(code_root, "R/fun_SEIRsimu.R"))
source(paste0(code_root, "R/fun_SEIRfitting_BST249.R"))
source(paste0(code_root, "R/fun_BTSetup_BST249.R"))
source(paste0(code_root, "R/init_cond.R"))
source(paste0(code_root, "R/fun_R0estimate.R"))
source(paste0(code_root, "R/fun_SEIRplot.R"))
source(paste0(code_root, "R/fun_Findzero.R"))
##
init_sets_list=get_init_sets_list(r0 = 0.23)
init_sets_list$daily_new_case <- sim1$Onset_expect
init_sets_list$daily_new_case_all <- c(sim1$Onset_expect, rep(0,8))
SEIRfitting(init_sets_list, randomize_startValue = T,
run_id = "main_analysis", output_ret = T, skip_MCMC=F)
